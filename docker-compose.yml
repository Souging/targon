version: '3.8'
services:
  # text-generation-service:
  #   image: ghcr.io/huggingface/text-generation-inference:1.3
  #   command: --model-id mlabonne/NeuralDaredevil-7B --max-input-length 3072 --max-total-tokens 4096
  #   volumes:
  #     - ./models:/data
  #   ports:
  #     - "8080:80"
  #   deploy:
  #     resources:
  #       reservat  ions:
  #         devices:
  #           - driver: nvidia
  #             capabilities: [gpu]
  #   shm_size: '1g'
  db:
    image: redis:6.2-alpine
    restart: always
    ports:
      - '6379:6379'
    command: redis-server --save 20 1 --loglevel warning --requirepass eYVX7EwVmmxKPCDmwMtyKVge8oLd2t81
    volumes: 
      - db:/data

volumes:
  db:
    driver: local
